**Техническое задание (ТЗ) на основу проекта контентного сайта со связкой SSP-DSP-Bidder, хранением контента в PostgreSQL и логированием в Kafka–ClickHouse, с возможностью деплоя без даунтайма**

---

## 1. ЦЕЛИ И ЗАДАЧИ

- Создать **контентный сайт** со сбором и отображением тематических статей.
- Организовать **рекламный аукцион** по схеме SSP ↔ DSP, с отдельным сервисом Bidder для определения ставок (пока фиксированных).
- **Хранить статьи** в базе **PostgreSQL**.
- **Логировать все действия** (обращения к сервисам, события) в **Kafka**, чтобы впоследствии **ClickHouse** сохранял эти логи для аналитики.
- Обеспечить **масштабируемость** и возможность **zero-downtime деплоя** сервисов.

---

## 2. ТРЕБОВАНИЯ К СИСТЕМЕ

### 2.1. Сбор контента

1. **Aggregator (Python)**
    - Поддержка автоматического сбора статей из внешних API (например, NewsAPI, Reddit RSS, Bing).
    - Хранение результатов (статей) в PostgreSQL.
    - Логирование действий (начала, завершения сбора, вставки статей и пр.) в Kafka.
    - Возможность запуска по расписанию (cron / Airflow).

### 2.2. Рекламная подсистема

1. **Bidder (Go)**
    - Предоставляет **фиксированную** ставку (CPM) по эндпоинту `/getBid`.
    - В будущем — возможность интеграции ML-моделей для динамического расчёта ставок.
    - Логирование в Kafka.

2. **DSP (Go)**
    - Принимает **OpenRTB 2.2**-запросы по эндпоинту `/openrtb2/auction`.
    - Получает ставку от Bidder.
    - Возвращает рекламный креатив (HTML/JS) с указанием CPM.
    - Логирование в Kafka.

3. **SSP (Go)**
    - Принимает аукционные запросы (например, `/ssp/auction`) и рассылает их параллельно нескольким DSP (OpenRTB).
    - Собирает отклики, **выбирает лучшие ставки** (либо топ-N).
    - Отправляет финальный ответ с выигравшей(ими) заявкой(ами).
    - Логирование в Kafka.

### 2.3. Фронтенд и сайт

1. **Website (Node.js)**
    - Отображение списка статей (берутся из PostgreSQL).
    - Предусмотрен рекламный слот, куда можно вставлять креатив, полученный от SSP.
    - Логирование пользовательских обращений (REST-эндпоинты и т.д.) в Kafka.

2. **Адаптивный дизайн** (Bootstrap или другой фреймворк).
    - Меню, навигация, мобильная адаптация.

### 2.4. Хранение данных

1. **PostgreSQL**
    - Таблица `articles` с основными полями (title, content, source_url, created_at, и т.д.).
    - Возможность расширения схемы (метаданные статей, теги).

2. **ClickHouse**
    - Хранение логов из Kafka (через Kafka Engine / Materialized View или Kafka Connect).
    - Таблица для логов (timestamp, service, level, message, …).

### 2.5. Логирование

1. **Kafka** (брокер)
    - Все сервисы отправляют логи в единый топик (`service-logs`).
    - Kafka-коннектор (или движок ClickHouse) считывает логи и пишет их в ClickHouse.

### 2.6. Деплой

1. **Docker** / **Kubernetes**
    - Каждый сервис (Aggregator, DSP, SSP, Bidder, Website) упакован в Docker-контейнер.
    - Zero-downtime деплой (rolling update / blue-green).
    - Можно использовать `docker-compose` для локальной разработки и тестов.

2. **Без даунтайма**:
    - При изменении версии сервисов поднимаются новые поды, проверяются readiness/liveness-пробы, переключается трафик.

---

## 3. ТРЕБОВАНИЯ К АРХИТЕКТУРЕ

1. Микросервисная структура: каждый сервис (Aggregator, DSP, SSP, Bidder, Website) независим, общаются по REST / HTTP.
2. Гибкая масштабируемость:
    - SSP, DSP, Website можно горизонтально масштабировать под нагрузку.
    - PostgreSQL, Kafka, ClickHouse — разворачивать кластерно при необходимости.
3. Надёжность и устойчивость к сбоям:
    - Обработка ошибок (логирование, возврат корректных статусов).
    - Запас по времени отклика (timeouts).

---

## 4. ОСНОВНОЙ ФУНКЦИОНАЛ

1. **Сбор и хранение статей**
    - По ключевым словам, конфигурация в `config.yaml`.
    - Регулярный запуск, вставка новых записей в БД.

2. **Рекламные запросы**
    - SSP ↔ DSP по OpenRTB 2.2.
    - DSP ↔ Bidder: получение CPM.
    - Выбор победителя SSP.

3. **Отображение контента**
    - На веб-сайте присутствуют страницы со статьями.
    - Рекламный блок (через SSP).

4. **Логирование**
    - Каждый запрос/действие — в Kafka.
    - Впоследствии логи доступны в ClickHouse для анализа.

5. **Деплой**
    - Docker + Kubernetes.
    - Rolling update без даунтайма.

---

## 5. РАСШИРЕНИЕ И БУДУЩЕЕ РАЗВИТИЕ

1. **ML-модель** в Bidder.
2. **Аналитические отчёты** на базе ClickHouse (интеграция с Grafana, Tableau и т.п.).
3. **Полнотекстовый поиск** по статьям (ElasticSearch или PostgreSQL FTS).
4. **Безопасность**: TLS, аутентификация, токены, ограничение доступа.

---

## 6. ИТОГ

Данное ТЗ описывает **микросервисную систему** для контентного сайта с рекламным аукционом. Включает в себя требования к хранению данных в PostgreSQL, логированию в Kafka, анализу логов в ClickHouse и деплою без простоя. На основе этого документа можно **формулировать задачи** в других чатах, разбивая проект на более мелкие подпроекты или расширяя функционал.