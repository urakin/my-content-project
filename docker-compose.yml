version: "3.8"
services:
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"

  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
    ports:
      - "9092:9092"

  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      - POSTGRES_DB=mydb
      - POSTGRES_USER=myuser
      - POSTGRES_PASSWORD=mypass
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./db/init_postgres.sql:/docker-entrypoint-initdb.d/init_postgres.sql

  clickhouse:
    image: clickhouse/clickhouse-server:23
    container_name: clickhouse
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse-data:/var/lib/clickhouse
  # При необходимости mount'им init_clickhouse.sql вручную

  aggregator:
    build: ./aggregator
    container_name: aggregator
    depends_on:
      - postgres
      - kafka
    # Здесь aggregator можно запускать вручную при необходимости
    # или всегда (например, собирает контент 1 раз при старте).
    # Если хотите cron-like поведение, можете не запускать его постоянно.
    # command: ["sleep", "3600"]  # заглушка вместо постоянного цикла

  bidder:
    build: ./bidder
    container_name: bidder
    depends_on:
      - kafka
    ports:
      - "8090:8090"

  dsp:
    build: ./dsp
    container_name: dsp
    depends_on:
      - bidder
      - kafka
    ports:
      - "8080:8080"

  ssp:
    build: ./ssp
    container_name: ssp
    depends_on:
      - dsp
      - kafka
    ports:
      - "3002:3002"

  website:
    build: ./website
    container_name: website
    depends_on:
      - postgres
      - kafka
    ports:
      - "3001:3001"

volumes:
  postgres-data:
  clickhouse-data:
